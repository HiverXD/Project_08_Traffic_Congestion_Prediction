{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97695f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from dataset.traffic_dataset import TrafficDataset\n",
    "from dataset.dataset_config import edge_index, edge_attr\n",
    "#from models.baselines import STGCN\n",
    "from models.STLinear import STLinear\n",
    "from models.STLinear_biased_models import STLinear_SPE\n",
    "from utils.Trainer import Trainer  \n",
    "import optuna\n",
    "\n",
    "# 2) collate_fn\n",
    "def collate_fn(batch_list):\n",
    "    xs = torch.stack([data.x for data in batch_list], dim=0)  # [B, T, E, C]\n",
    "    ys = torch.stack([data.y for data in batch_list], dim=0)  # [B, n_pred, E, D]\n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d59f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) dataset\n",
    "dataset_np = np.load('dataset/traffic_dataset_13_smoothen.npy', allow_pickle=True)\n",
    "dataset = TrafficDataset(dataset_np, window=12, randomize=False)\n",
    "\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "val_size   = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=512, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=512, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# shape test\n",
    "x0, y0 = next(iter(train_loader))\n",
    "B, T, E, C_in = x0.shape\n",
    "_, n_pred, _, C_out = y0.shape\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Dataset shapes: x0={x0.shape}, y0={y0.shape}, device={device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82158ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Optuna Objective\n",
    "def objective(trial):\n",
    "    # --- Hyperparameter suggestions ---\n",
    "    # common\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0.1, 0.3)\n",
    "    # hyperparameter for GNN\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [17, 33, 65])\n",
    "    K = trial.suggest_int(\"K\", 1, 3)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 4)\n",
    "    num_heads = trial.suggest_int(\"num_heads\", 1,2,4)\n",
    "\n",
    "    input_embedding_dim = trial.suggest_categorical(\"input_embedding_dim\", [16, 32, 64])\n",
    "    tod_embedding_dim = trial.suggest_categorical(\"tod_embedding_dim\", [16, 32, 64])\n",
    "    dow_embedding_dim = trial.suggest_categorical(\"dow_embedding_dim\", [16, 32, 64])\n",
    "    spatial_embedding_dim = trial.suggest_categorical(\"spatial_embedding_dim\", [0, 16, 32, 64])\n",
    "    adaptive_embedding_dim = trial.suggest_categorical(\"adaptive_embedding_dim\", [0, 16, 32, 64])\n",
    "    spe_dim = trial.suggest_categorical(\"spe_dim\", [16, 32, 64])\n",
    "    spe_out_dim = trial.suggest_categorical(\"spe_out_dim\", [16, 32, 64])\n",
    "\n",
    "\n",
    "    model = STLinear_SPE(\n",
    "        num_nodes =E,\n",
    "        kernel_size=kernel_size, #odd number\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        input_embedding_dim = input_embedding_dim,\n",
    "        tod_embedding_dim = tod_embedding_dim,\n",
    "        dow_embedding_dim = dow_embedding_dim,\n",
    "        spatial_embedding_dim = spatial_embedding_dim,\n",
    "        adaptive_embedding_dim = adaptive_embedding_dim,\n",
    "        spe_dim = spe_dim,\n",
    "        spe_out_dim = spe_out_dim\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.L1Loss()\n",
    "\n",
    "    # --- run Trainer ---\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        epochs=50,\n",
    "        device=device,\n",
    "        print_interval=0,    # no print\n",
    "        plot_interval=0,     # no plot\n",
    "        early_stopping_patience=4\n",
    "    )\n",
    "    trainer.fit()\n",
    "\n",
    "    # return best loss\n",
    "    valid_loss = trainer.get_best_valid_loss() \n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac651eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Run Optuna Study\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)\n",
    ")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 6) check best result\n",
    "print(\"Best validation loss:\", study.best_value)\n",
    "print(\"Best hyperparameters:\")\n",
    "for k,v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f361534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) train with best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_model = STLinear_SPE(\n",
    "    num_nodes=E,\n",
    "    # GNN\n",
    "    kernel_size=best_params['kernel_size'],        # odd number\n",
    "    num_heads=best_params['num_heads'],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout=best_params['dropout'],\n",
    "    # embedding dim\n",
    "    input_embedding_dim=best_params['input_embedding_dim'],\n",
    "    tod_embedding_dim=best_params['tod_embedding_dim'],\n",
    "    dow_embedding_dim=best_params['dow_embedding_dim'],\n",
    "    spatial_embedding_dim=best_params['spatial_embedding_dim'],\n",
    "    adaptive_embedding_dim=best_params['adaptive_embedding_dim'],\n",
    "    spe_dim=best_params['spe_dim'],\n",
    "    spe_out_dim=best_params['spe_out_dim']\n",
    ").to(device)\n",
    "\n",
    "best_opt = AdamW(best_model.parameters(), lr=5e-5, weight_decay=best_params['weight_decay'])\n",
    "trainer = Trainer(\n",
    "    model=best_model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=val_loader,\n",
    "    optimizer=best_opt,\n",
    "    criterion=torch.nn.L1Loss(),\n",
    "    epochs=60,\n",
    "    device=device,\n",
    "    print_interval=0,\n",
    "    plot_interval=2,\n",
    "    auto_save=True,\n",
    "    save_dir='./final_model'\n",
    ")\n",
    "trainer.fit()\n",
    "hist = trainer.get_history()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist['train_loss'], label='Train Loss')\n",
    "plt.plot(hist['valid_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
